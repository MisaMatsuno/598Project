{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0njVM2OnAVmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(1, 256, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(256, 128, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Dropout(p=0.1),\n",
        "            \n",
        "            nn.MaxPool1d(kernel_size=8), # 216/8=27\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool1d(kernel_size=9), # 27/9=3\n",
        "\n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 3\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr9R0Y9wo8uq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvkuS7uM-ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=3, padding=1), # (216 + 2*1 - 1*(3-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(32, 32, kernel_size=3, padding=1), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3), # 216/3=72\n",
        "            \n",
        "            nn.Dropout(p=0.1),\n",
        "                        \n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(64, 64, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3), # 72/3=24\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 3\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3), # 24/3=8\n",
        "\n",
        "            nn.Conv1d(256, 512, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv1d(512, 1024, kernel_size=3, padding=1), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=2), # 8/2=4\n",
        "            \n",
        "            nn.Flatten(),\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUv9oo34jlB3",
        "colab_type": "text"
      },
      "source": [
        "0.7376237623762376"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE_aUUPKjnl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNet, self).__init__()\n",
        "        # Add more conv layers with increasing output channels\n",
        "        # Add normalization layers after conv layers (nn.BatchNorm2d)\n",
        "        # Also experiment with kernel size in conv2d layers (say 3\n",
        "        # inspired from VGGNet)\n",
        "    \n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(13, 256, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(256, 128, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Dropout(p=0.1),\n",
        "            \n",
        "            nn.MaxPool1d(kernel_size=3), # 216/3=72\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool1d(kernel_size=3), # 72/3=24\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool1d(kernel_size=3), # 24/3=8\n",
        "\n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 3\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool1d(kernel_size=2), # 8/2=4\n",
        "            \n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Add more linear (fc) layers\n",
        "        # Add normalization layers after linear and\n",
        "        # experiment inserting them before or after ReLU (nn.BatchNorm1d)\n",
        "        \n",
        "        self.fc_net = nn.Sequential(\n",
        "            # nn.Linear(4*1024, 2*1024),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            # nn.BatchNorm1d(2*1024),\n",
        "\n",
        "            # nn.Linear(2*256, 256),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            # nn.BatchNorm1d(256),\n",
        "\n",
        "\n",
        "            nn.Linear(128*4, 4),\n",
        "            nn.BatchNorm1d(4),\n",
        "            # nn.Softmax(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_net(x)\n",
        "        x = self.fc_net(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the nn.module class defined above:\n",
        "net = BaseNet()\n",
        "net = net.float()\n",
        "if IS_GPU:\n",
        "    net = net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvfvj48pNLTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffled_featuresHMM = [f.T for f in shuffled_featuresHMM]\n",
        "print(shuffled_featuresHMM[0].shape)\n",
        "shuffle_data_labelsHMM = [data_labelsHMM[i] for i in rang]\n",
        "print(len(shuffled_featuresHMM), len(shuffle_data_labelsHMM))\n",
        "\n",
        "totLen = len(shuffled_featuresHMM)\n",
        "train_feature = shuffled_featuresHMM[0:int(totLen*0.8)]\n",
        "train_label = shuffle_data_labelsHMM[0:int(totLen*0.8)]\n",
        "test_feature = shuffled_featuresHMM[int(totLen*0.8):]\n",
        "test_label = shuffle_data_labelsHMM[int(totLen*0.8):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RysOVPASgJ00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rang_train = np.arange(0, len(data_mfccs_train))\n",
        "shuffle(rang_train)\n",
        "train_feature = [data_mfccs_train[i] for i in rang_train]\n",
        "train_label = [data_labels_train[i] for i in rang_train]\n",
        "\n",
        "rang_test = np.arange(0, len(data_mfccs_test))\n",
        "shuffle(rang_test)\n",
        "test_feature = [data_mfccs_test[i] for i in rang_test]\n",
        "test_label = [data_labels_test[i] for i in rang_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6j3Ba7hwzsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "3 0.6666666666666666\n",
        "6 0.7241379310344828\n",
        "7 0.7030651340996169\n",
        "8 0.7490421455938697\n",
        "9 0.7452107279693486\n",
        "10 0.7452107279693486"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz3aWPp70JsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "likelihoods = []\n",
        "BICs = []\n",
        "for n_comp in range(3,30):\n",
        "  lr = hmm.GaussianHMM(n_components=n_comp, covariance_type=\"diag\")\n",
        "  lr.startprob_ = np.zeros(n_comp)\n",
        "  lr.startprob_[0] = 1\n",
        "  lr.transmat_ = get_transition_left_right(n_comp)\n",
        "  # get each class's training data\n",
        "  lengths = len(train_feature)*[train_feature[0].shape[0]]\n",
        "  trainData = np.hstack(train_feature[:200])\n",
        "  print(\"trainData.shape\", trainData.shape)\n",
        "  lr.fit(trainData.T)\n",
        "  score = lr.score(trainData.T)\n",
        "  BIC = np.log(trainData.shape[1])*4 - 2*np.log(score)\n",
        "  likelihoods.append(score)\n",
        "  BICs.append(BIC)\n",
        "  print(\"Model with n_comp \" , n_comp , \" scored \" , score)\n",
        "  print(\"Model with n_comp \" , n_comp , \" BIC \" , BIC)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osqnMvsPqUiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = hmm.GaussianHMM(n_components=n_comp, covariance_type=\"diag\")\n",
        "lr.startprob_ = np.zeros(n_comp)\n",
        "lr.startprob_[0] = 1\n",
        "lr.transmat_ = get_transition_left_right(n_comp)\n",
        "# get each class's training data\n",
        "lengths = len(train_feature)*[train_feature[0].shape[0]]\n",
        "trainData = (train_feature[1000])\n",
        "print(train_label[1000])\n",
        "print(\"trainData.shape\", trainData.shape)\n",
        "lr.fit(trainData.T)\n",
        "ps = lr.predict(trainData.T)\n",
        "plt.scatter(np.arange(len(ps)), ps+1)\n",
        "plt.xlabel('frames')\n",
        "plt.ylabel('state number')\n",
        "plt.title('Sample State Transition of Emotion \"Angry\"')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwySlmNAo9-N",
        "colab_type": "text"
      },
      "source": [
        "0.7970297029702971"
      ]
    }
  ]
}