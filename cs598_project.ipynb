{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs598 project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmCbxoDrADcF"
      },
      "source": [
        "# Google Colab setup with Google Drive folder\n",
        "\n",
        "This notebook provides the code you need to set up Google Colab to run and import files from within a Google Drive folder.\n",
        "\n",
        "This will allow you to upload assignment code to your Google Drive and then run the code on Google Colab machines (with free GPUs if needed). \n",
        "\n",
        "You will need to create a folder in your Google Drive to hold your assignments and you will need to open Colaboratory within this folder before running the set up code (check the link above to see how)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zWhrmhqVCyGH"
      },
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "This will allow the Colab machine to access Google Drive folders by mounting the drive on the machine. You will be asked to copy and paste an authentication code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wv2oKmF9AJtI",
        "outputId": "ce64c1c1-b21a-4524-f5a0-a26aa674c153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKGxaMcmP_Et",
        "colab_type": "code",
        "outputId": "8ee61ecc-8746-46ff-c6cc-891630550585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Qs04PPwDOFy"
      },
      "source": [
        "# Change directory to allow imports\n",
        "\n",
        "\n",
        "As noted above, you should create a Google Drive folder to hold all your assignment files. You will need to add this code to the top of any python notebook you run to be able to import python files from your drive assignment folder (you should change the file path below to be your own assignment folder)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UA2-UyfpEc9O",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/CS598\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyRCWAIyRHWc",
        "colab_type": "code",
        "outputId": "10f1d2c4-1c2d-4852-dc86-83e2bbcfc889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls # Check if this is your MP4 folder"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mRADVESS\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJOCaUMilRz_",
        "colab_type": "text"
      },
      "source": [
        "# Copy data to local dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90MxG_eRla0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /dataCS5981\n",
        "!cp -r RADVESS/ /data\n",
        "# !tar -xf /data/cifar100.tar.gz -C /data/\n",
        "# !cp data/test.tar.gz /data\n",
        "# !tar -xf /data/test.tar.gz -C /data\n",
        "# !cp data/train.tar.gz /data\n",
        "# !tar -xf /data/train.tar.gz -C /data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvFEFItpl98p",
        "colab_type": "code",
        "outputId": "81db72ec-38dd-41a3-db3a-ef43a42abe0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "ls /data/RADVESS"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mActor_01\u001b[0m/  \u001b[01;34mActor_06\u001b[0m/  \u001b[01;34mActor_11\u001b[0m/  \u001b[01;34mActor_16\u001b[0m/  \u001b[01;34mActor_21\u001b[0m/\n",
            "\u001b[01;34mActor_02\u001b[0m/  \u001b[01;34mActor_07\u001b[0m/  \u001b[01;34mActor_12\u001b[0m/  \u001b[01;34mActor_17\u001b[0m/  \u001b[01;34mActor_22\u001b[0m/\n",
            "\u001b[01;34mActor_03\u001b[0m/  \u001b[01;34mActor_08\u001b[0m/  \u001b[01;34mActor_13\u001b[0m/  \u001b[01;34mActor_18\u001b[0m/  \u001b[01;34mActor_23\u001b[0m/\n",
            "\u001b[01;34mActor_04\u001b[0m/  \u001b[01;34mActor_09\u001b[0m/  \u001b[01;34mActor_14\u001b[0m/  \u001b[01;34mActor_19\u001b[0m/  \u001b[01;34mActor_24\u001b[0m/\n",
            "\u001b[01;34mActor_05\u001b[0m/  \u001b[01;34mActor_10\u001b[0m/  \u001b[01;34mActor_15\u001b[0m/  \u001b[01;34mActor_20\u001b[0m/  Audio_Speech_Actors_01-24.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DDU5aVgR9QBx"
      },
      "source": [
        "# Set up GPU and PyTorch\n",
        "\n",
        "First, ensure that your notebook on Colaboratory is set up to use GPU. After opening the notebook on Colaboratory, go to Edit>Notebook settings, select Python 3 under \"Runtime type,\" select GPU under \"Hardware accelerator,\" and save.\n",
        "\n",
        "Next, install PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kjbQtzKT9Uc2",
        "outputId": "582f7387-b567-4364-fa2e-d7b8b489d56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "!pip3 install torch torchvision\n",
        "!pip3 install librosa"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.17.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.30.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u_BekZYY9Vzx"
      },
      "source": [
        "Make sure that pytorch is installed and works with GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8TXSJWQa9efx",
        "outputId": "29a657b8-ffaf-4b14-ff26-6906c13b22da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "a = torch.Tensor([1]).cuda()\n",
        "print(a)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo0txeT04X3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.linalg as lg\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile as wav\n",
        "import scipy\n",
        "import sys\n",
        "import os\n",
        "from random import shuffle\n",
        "import librosa\n",
        "import librosa.display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEeRNsCjRXZK",
        "colab_type": "code",
        "outputId": "1ee25172-ac7b-48ae-a7d1-046dfddbaa44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znXWR6oWyl-B",
        "colab_type": "code",
        "outputId": "7270f4aa-872f-481a-f851-d519bdc6a864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "test(model, criterion)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-317ba06cc91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3yJHzFhp0Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_names = []\n",
        "data_labels = []\n",
        "data_mfccs = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFIhYnKzp4PG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotionDict = {'happy': 0, 'sad': 1, 'angry': 2, 'fearful': 3}\n",
        "\n",
        "for dirs in os.listdir('/data/RADVESS/'):\n",
        "    if os.path.isdir('/data/RADVESS/'+ dirs):\n",
        "      files = os.listdir('/data/RADVESS/'+ dirs)\n",
        "    else:\n",
        "      continue\n",
        "    for file in files:\n",
        "        f = file.split('-')\n",
        "        inEmotion = False\n",
        "        if(f[2]=='03'):\n",
        "            data_labels.append(emotionDict['happy'])\n",
        "            inEmotion = True\n",
        "        elif(f[2]=='04'):\n",
        "            data_labels.append(emotionDict['sad'])\n",
        "            inEmotion = True\n",
        "        elif(f[2]=='05'):\n",
        "            data_labels.append(emotionDict['angry'])\n",
        "            inEmotion = True\n",
        "        elif(f[2]=='06'):\n",
        "            data_labels.append(emotionDict['fearful'])\n",
        "            inEmotion = True\n",
        "        if inEmotion == True:\n",
        "            data_names.append(file)\n",
        "            # load data\n",
        "            data, sample_rate = librosa.load('RADVESS/'+dirs+'/'+ file, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5) # data is 110250\n",
        "            # get mfcc features\n",
        "            mfccs = librosa.feature.mfcc(y=data.astype(dtype=float), sr=sample_rate, n_mfcc=13) # 13 x 216\n",
        "            data_mfccs.append(mfccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naLR6qWWp7Si",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb08bd1d-cb26-48cc-aa0e-a947af5b79ef"
      },
      "source": [
        "# Convert 2d mfcc features to 1d\n",
        "features = [np.mean(mfcc, axis=0) for mfcc in data_mfccs] # (216,)\n",
        "# features = features.astype(dtype='double')\n",
        "print(len(features), features[0].shape, len(data_names), len(data_labels))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768 (216,) 768 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha0M8Krxp9RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1aabcb2b-35e4-49d5-b441-2b86c9aee3b9"
      },
      "source": [
        "# shuffle data\n",
        "z = list(zip(features, data_labels))\n",
        "shuffle(z)\n",
        "features, data_labels = zip(*z)\n",
        "\n",
        "# split data into train and test set\n",
        "train_feature = features[0:int(len(features)*0.8)]\n",
        "test_feature = features[int(len(features)*0.8):]\n",
        "train_label = data_labels[0:int(len(data_labels)*0.8)]\n",
        "test_label = data_labels[int(len(data_labels)*0.8):]\n",
        "print(len(train_feature),len(test_feature),len(train_label),len(test_label))\n",
        "\n",
        "# Convert list to array\n",
        "train_feature = np.array(train_feature)\n",
        "test_feature = np.array(test_feature)\n",
        "print(train_feature.shape, train_feature[0].shape)\n",
        "print(len(train_label))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "614 154 614 154\n",
            "(614, 216) (216,)\n",
            "614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIJrfpQmp_Cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.utils.data\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "IS_GPU = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLHbpHM6qBFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNet, self).__init__()\n",
        "        # Add more conv layers with increasing output channels\n",
        "        # Add normalization layers after conv layers (nn.BatchNorm2d)\n",
        "        # Also experiment with kernel size in conv2d layers (say 3\n",
        "        # inspired from VGGNet)\n",
        "    \n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(1, 256, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(256, 128, kernel_size=5, padding=2), # (216 + 2*2 - 1*(5-1) - 1)/1+1= 216\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Dropout(p=0.1),\n",
        "            \n",
        "            nn.MaxPool1d(kernel_size=8), # 216/8=27\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2), # (27 + 2*2 - 1*(5-1) - 1)/1+1= 27\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Add more linear (fc) layers\n",
        "        # Add normalization layers after linear and\n",
        "        # experiment inserting them before or after ReLU (nn.BatchNorm1d)\n",
        "        \n",
        "        self.fc_net = nn.Sequential(\n",
        "            nn.Linear(27*128,4),\n",
        "            nn.Softmax(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_net(x)\n",
        "        x = self.fc_net(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the nn.module class defined above:\n",
        "net = BaseNet()\n",
        "net = net.float()\n",
        "if IS_GPU:\n",
        "    net = net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocdFNJblqDRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# 3. Define a Loss function and optimizer\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "# Here we use Cross-Entropy loss and SGD with momentum.\n",
        "# The CrossEntropyLoss criterion already includes softmax within its\n",
        "# implementation. That's why we don't use a softmax in our model\n",
        "# definition.\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Tune the learning rate.\n",
        "# See whether the momentum is useful or not\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "plt.ioff()\n",
        "fig = plt.figure()\n",
        "train_loss_over_epochs = []\n",
        "val_accuracy_over_epochs = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNJydigDqFJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "e6f2c51c-5067-41d4-f77f-f74e702fe3a0"
      },
      "source": [
        "# Train the network\n",
        "n_batches = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i in range(int(train_feature.shape[0]/n_batches)+1):\n",
        "        # Local batches and labels\n",
        "        if (i+1)*n_batches > train_feature.shape[0]:\n",
        "            inputs, labels = train_feature[i*n_batches:,:], train_label[i*n_batches:]\n",
        "        else:\n",
        "            inputs, labels = train_feature[i*n_batches:(i+1)*n_batches,:], train_label[i*n_batches:(i+1)*n_batches]\n",
        "\n",
        "        inputs = torch.from_numpy(inputs)\n",
        "        labels = torch.from_numpy(np.array(labels))\n",
        "\n",
        "        if IS_GPU:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs = Variable((inputs))\n",
        "        labels = Variable(((labels)))\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        inputs = torch.unsqueeze(inputs,1)\n",
        "        outputs = net(inputs.float())\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss/=int(train_feature.shape[0]/n_batches)+1\n",
        "    print('[%d] loss: %.3f' %\n",
        "          (epoch + 1, running_loss))\n",
        "\n",
        "    # Scale of 0.0 to 100.0\n",
        "    # Calculate validation set accuracy of the existing model\n",
        "#     val_accuracy, val_classwise_accuracy = \\\n",
        "#         calculate_val_accuracy(valloader, IS_GPU)\n",
        "#     print('Accuracy of the network on the val images: %d %%' % (val_accuracy))\n",
        "\n",
        "    train_loss_over_epochs.append(running_loss)\n",
        "#     val_accuracy_over_epochs.append(val_accuracy)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "# Plot train loss over epochs and val set accuracy over epochs\n",
        "# Nothing to change here\n",
        "# -------------\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.ylabel('Train loss')\n",
        "plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n",
        "plt.title('train loss and val accuracy')\n",
        "plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "# plt.plot(np.arange(EPOCHS), val_accuracy_over_epochs, 'b-')\n",
        "# plt.ylabel('Val accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "# plt.grid(True)\n",
        "# plt.savefig(\"plot.png\")\n",
        "# plt.close(fig)\n",
        "print('Finished Training')\n",
        "# -------------"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1] loss: 1.310\n",
            "[2] loss: 1.225\n",
            "[3] loss: 1.197\n",
            "[4] loss: 1.139\n",
            "[5] loss: 1.093\n",
            "[6] loss: 1.072\n",
            "[7] loss: 1.034\n",
            "[8] loss: 1.028\n",
            "[9] loss: 0.994\n",
            "[10] loss: 0.999\n",
            "[11] loss: 0.972\n",
            "[12] loss: 0.955\n",
            "[13] loss: 0.950\n",
            "[14] loss: 0.935\n",
            "[15] loss: 0.915\n",
            "[16] loss: 0.901\n",
            "[17] loss: 0.898\n",
            "[18] loss: 0.890\n",
            "[19] loss: 0.885\n",
            "[20] loss: 0.906\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHKthlmWqHkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c6675c32-6e8d-4f9e-8402-37c69668a867"
      },
      "source": [
        "########################################################################\n",
        "# 5. Try the network on test data, and create .csv file\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "########################################################################\n",
        "\n",
        "# Check out why .eval() is important!\n",
        "# https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744/2\n",
        "net.eval()\n",
        "\n",
        "total = 0\n",
        "predictions = []\n",
        "# for i in range(test_feature.shape[0]):\n",
        "data, label = test_feature, test_label\n",
        "\n",
        "data = torch.from_numpy(data)\n",
        "data = torch.unsqueeze(data,1)\n",
        "print(data.shape)\n",
        "\n",
        "if IS_GPU:\n",
        "  data = data.cuda()\n",
        "  # labels = labels.cuda()\n",
        "\n",
        "data = Variable(data)\n",
        "outputs = net(data.float())\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "predictions.extend(list(predicted.cpu().numpy()))\n",
        "#     total += label.size(0)\n",
        "acc = 0\n",
        "for l_i, label in enumerate(predictions):\n",
        "    if label == test_label[l_i]:\n",
        "        acc += 1\n",
        "#     print([str(l_i), str(label)], test_label[l_i])\n",
        "print(\"accuracy\", acc/len(test_label))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([154, 1, 216])\n",
            "accuracy 0.5714285714285714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}